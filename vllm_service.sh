#!/bin/bash
# ROCm + vLLM + ModelScope ä¸€é”®ç®¡ç†è„šæœ¬ï¼ˆæ”¯æŒå®¹å™¨å†…ä¸‹è½½&æœåŠ¡å¯åŠ¨ï¼‰
# ä½¿ç”¨å‰ï¼šç¡®ä¿æœ‰ä¸€ä¸ªåä¸º rocm çš„é•œåƒï¼ˆæˆ–æ”¹æˆä½ çš„é•œåƒåï¼‰ï¼Œå…¶ä¸­å·²åŒ…å« vLLMã€‚
# æ³¨æ„ï¼šæœ¬è„šæœ¬æ”¹ä¸ºä½¿ç”¨ ModelScope ä¸‹è½½æ¨¡å‹ï¼Œä¸å†ä¾èµ– HF_TOKENã€‚

# ======= é…ç½®åŒº =======
CONTAINER_NAME="rocm"
# ModelScope çš„æ¨¡å‹IDï¼ˆä½ è¦çš„ 3.1 8B Instructï¼‰
MS_MODEL_ID="LLM-Research/Meta-Llama-3.1-8B-Instruct"

# æ¨¡å‹æœ¬åœ°è½åœ°ç›®å½•ï¼ˆæŒ‚è½½å·ï¼Œå®¹å™¨å†…å¤–ä¸€è‡´ï¼‰
MODEL_DIR_HOST="/shared-docker/models/Meta-Llama-3.1-8B-Instruct"
MODEL_DIR_IN_CONTAINER="$MODEL_DIR_HOST"   # å› ä¸ºæŒ‚äº†åŒä¸€è·¯å¾„ï¼Œå®¹å™¨å†…å°±æ˜¯è¿™ä¸ªç»å¯¹è·¯å¾„

# vLLM served åç§° & ç«¯å£
SERVED_MODEL_NAME="llama-3.1-8b-instruct"
PORT="8001"

# æ—¥å¿—
LOG_DIR="/root/vllm_logs"
PID_FILE="$LOG_DIR/vllm_docker.pid"

# ä½ ç°æœ‰çš„ ROCm/vLLM åŸºç¡€é•œåƒåï¼ˆæ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
IMAGE_NAME="rocm"

# é¢å¤–æŒ‚è½½ï¼ˆHF ç¼“å­˜å¯é€‰ï¼ŒModelScope æˆ‘ä»¬ç”¨è‡ªå®šä¹‰ç›®å½•ï¼‰
HF_CACHE_HOST="$HOME/.cache/huggingface"
MODELSCOPE_CACHE_HOST="/shared-docker/modelscope_cache"

# vLLM è¿è¡Œå‚æ•°ï¼ˆæŒ‰éœ€è°ƒæ•´ï¼‰
MAX_MODEL_LEN="131072"               # Llama3.1 æ”¯æŒ 128Kï¼Œä¸Šä¸‹å–æ•´ç»™ 131072
GPU_MEM_UTIL="0.95"

mkdir -p "$LOG_DIR" "$MODEL_DIR_HOST" "$MODELSCOPE_CACHE_HOST" "$HF_CACHE_HOST"

# ======= å‡½æ•°åŒº =======

recreate_container() {
    echo "ğŸ”§ é‡æ–°åˆ›å»ºå®¹å™¨ï¼ˆç«¯å£æ˜ å°„æ¨¡å¼ï¼‰..."
    docker exec $CONTAINER_NAME pkill -f "vllm serve" 2>/dev/null || true
    docker stop $CONTAINER_NAME 2>/dev/null || true
    docker rm $CONTAINER_NAME 2>/dev/null || true

    mkdir -p /shared-docker
    mkdir -p "$HF_CACHE_HOST"

    docker run -it -d \
      --name $CONTAINER_NAME \
      --device=/dev/kfd \
      --device=/dev/dri \
      --group-add=video \
      --ipc=host \
      --cap-add=SYS_PTRACE \
      --security-opt seccomp=unconfined \
      -p 8000:8000 -p 8888:8888 -p 30000:30000 -p 8001:8001 \
      -v /shared-docker:/shared-docker \
      -v "$HF_CACHE_HOST":/root/.cache/huggingface \
      -v "$MODELSCOPE_CACHE_HOST":/root/.cache/modelscope \
      "$IMAGE_NAME"

    if [ $? -eq 0 ]; then
        echo "âœ… å®¹å™¨é‡æ–°åˆ›å»ºæˆåŠŸ"
        sleep 5
        return 0
    else
        echo "âŒ å®¹å™¨åˆ›å»ºå¤±è´¥"
        return 1
    fi
}

ensure_port_mapping() {
  # æ£€æŸ¥ rocm æ˜¯å¦å·²å‘å¸ƒ 8001
  if ! docker ps --format '{{.Names}}\t{{.Ports}}' \
      | grep -qE "^$CONTAINER_NAME\s+.*8001->8001"; then
    echo "âš ï¸  æ£€æµ‹åˆ°å®¹å™¨ $CONTAINER_NAME æœªå‘å¸ƒç«¯å£ 8001ï¼Œè‡ªåŠ¨é‡å»ºå®¹å™¨..."
    recreate_container || {
      echo "âŒ è‡ªåŠ¨é‡å»ºå®¹å™¨å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ‰§è¡Œï¼š$0 container recreate"; exit 1;
    }
  fi
}


ensure_modelscope_and_download() {
    echo "ğŸ“¦ ç¡®è®¤å®¹å™¨å†…å·²å®‰è£… ModelScopeï¼Œå¹¶ä¸‹è½½æ¨¡å‹åˆ°æŒä¹…å·..."
    if ! docker ps | grep -q $CONTAINER_NAME; then
        echo "âŒ å®¹å™¨ $CONTAINER_NAME æœªè¿è¡Œï¼Œè¯·å…ˆ: $0 container recreate æˆ– $0 container start"
        exit 1
    fi

    # å®¹å™¨å†…å®‰è£… modelscopeï¼ˆè‹¥å·²å®‰è£…ä¼šè·³è¿‡ï¼‰
    docker exec $CONTAINER_NAME bash -lc "
        python -c 'import modelscope' 2>/dev/null || pip install -U modelscope
    " || {
        echo "âŒ å®‰è£… modelscope å¤±è´¥"; exit 1;
    }

    # ä¸‹è½½ï¼ˆä½¿ç”¨ --local_dir æŠŠæƒé‡ç›´æ¥è½åˆ°æŒ‚è½½å·é‡Œï¼‰
    if docker exec $CONTAINER_NAME test -f \"$MODEL_DIR_IN_CONTAINER/config.json\"; then
        echo "âœ… å·²æ£€æµ‹åˆ°æœ¬åœ°æ¨¡å‹: $MODEL_DIR_IN_CONTAINER"
    else
        echo "â¬‡ï¸  æ­£åœ¨ä¸‹è½½ $MS_MODEL_ID åˆ° $MODEL_DIR_IN_CONTAINER ..."
        docker exec $CONTAINER_NAME bash -lc "
            mkdir -p \"$MODEL_DIR_IN_CONTAINER\"
            modelscope download --model \"$MS_MODEL_ID\" --local_dir \"$MODEL_DIR_IN_CONTAINER\"
        " || { echo "âŒ ModelScope ä¸‹è½½å¤±è´¥"; exit 1; }
        echo "âœ… ä¸‹è½½å®Œæˆ"
    fi
}

start_vllm() {
    echo "ğŸš€ å¯åŠ¨ vLLMï¼ˆModelScope æœ¬åœ°æ¨¡å‹ï¼‰..."
    if ! docker ps | grep -q $CONTAINER_NAME; then
        echo "âŒ å®¹å™¨æœªè¿è¡Œ"; return 1; fi
    ensure_port_mapping
    
    if docker exec $CONTAINER_NAME pgrep -f "vllm serve" >/dev/null; then
        echo "âŒ vLLM å·²åœ¨è¿è¡Œ"; return 1; fi

    # å…ˆä¿è¯æ¨¡å‹å¯ç”¨
    ensure_modelscope_and_download

    # å¯åŠ¨ vLLMï¼ˆç”¨æœ¬åœ°ç›®å½•ä½œä¸º --modelï¼‰
    nohup docker exec $CONTAINER_NAME bash -lc "
        mkdir -p /app/logs
        cd /app
        nohup vllm serve \"$MODEL_DIR_IN_CONTAINER\" \
            --host 0.0.0.0 \
            --port $PORT \
            --served-model-name \"$SERVED_MODEL_NAME\" \
            --max-model-len $MAX_MODEL_LEN \
            --gpu-memory-utilization $GPU_MEM_UTIL \
            --enable-chunked-prefill \
            > /app/logs/vllm.log 2>&1 & echo \$! > /app/vllm.pid
        echo 'vLLM æœåŠ¡å·²åœ¨å®¹å™¨å†…å¯åŠ¨'
    " > "$LOG_DIR/docker_exec.log" 2>&1 &

    echo $! > "$PID_FILE"
    echo "âœ… å¯åŠ¨å‘½ä»¤å·²å‘é€ï¼Œç­‰å¾…æœåŠ¡å°±ç»ª..."
    sleep 15
    check_service
}

stop_vllm() {
    echo "ğŸ›‘ åœæ­¢ vLLM..."
    docker exec $CONTAINER_NAME bash -lc '
        if [ -f /app/vllm.pid ]; then
            PID=$(cat /app/vllm.pid)
            if kill -0 $PID 2>/dev/null; then
                kill -TERM $PID; sleep 5
                kill -0 $PID 2>/dev/null && kill -KILL $PID
            fi
            rm -f /app/vllm.pid
        else
            pkill -f "vllm serve" || true
        fi
        echo "vLLM å·²åœæ­¢"
    '
    rm -f "$PID_FILE"
    echo "âœ… vLLM æœåŠ¡å·²åœæ­¢"
}

restart_vllm(){ stop_vllm; sleep 3; start_vllm; }

check_service() {
    echo "ğŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
    docker ps | grep -q $CONTAINER_NAME && echo "âœ… å®¹å™¨è¿è¡Œä¸­" || { echo "âŒ å®¹å™¨æœªè¿è¡Œ"; return 1; }

    if docker exec $CONTAINER_NAME pgrep -f "vllm serve" >/dev/null; then
        PID=$(docker exec $CONTAINER_NAME pgrep -f "vllm serve")
        echo "âœ… vLLM è¿›ç¨‹è¿è¡Œä¸­ (PID: $PID)"
    else
        echo "âŒ vLLM è¿›ç¨‹æœªè¿è¡Œ"; return 1;
    fi

    echo "ğŸŒ å®¹å™¨å†… API æ£€æŸ¥..."
    docker exec $CONTAINER_NAME curl -s --connect-timeout 5 "http://localhost:$PORT/v1/models" >/dev/null && \
        echo "âœ… å®¹å™¨å†… API æ­£å¸¸" || { echo "âŒ å®¹å™¨å†… API å¼‚å¸¸"; return 1; }

    echo "ğŸŒ å®¿ä¸»æœº API æ£€æŸ¥..."
    curl -s --connect-timeout 5 "http://localhost:$PORT/v1/models" >/dev/null && \
        echo "âœ… å®¿ä¸»æœº API æ­£å¸¸ï¼›æµ‹è¯•ï¼šcurl http://localhost:$PORT/v1/models" || {
        echo "âŒ å®¿ä¸»æœº API æ— å“åº”ï¼Œå»ºè®®ï¼š$0 container recreate"; return 1; }
}

show_logs() {
    echo "ğŸ“ vLLM æ—¥å¿—ï¼ˆå®¹å™¨å†…æœ€è¿‘ 50 è¡Œï¼‰:"
    docker exec $CONTAINER_NAME bash -lc 'test -f /app/logs/vllm.log && tail -50 /app/logs/vllm.log || echo "æ— æ—¥å¿—"'
    echo -e "\nğŸ“ å®¿ä¸»æœºæ‰§è¡Œæ—¥å¿—:"
    test -f "$LOG_DIR/docker_exec.log" && tail -100 "$LOG_DIR/docker_exec.log" || echo "æ— å®¿ä¸»æœºæ—¥å¿—"
}

follow_logs(){ docker exec -it $CONTAINER_NAME bash -lc 'tail -f /app/logs/vllm.log'; }

test_service() {
    echo "ğŸ§ª æµ‹è¯• /v1/chat/completions..."
    start_time=$(date +%s.%3N)
    resp=$(curl -s -X POST "http://localhost:$PORT/v1/chat/completions" \
      -H "Content-Type: application/json" -d "{
        \"model\": \"$SERVED_MODEL_NAME\",
        \"messages\": [{\"role\":\"user\",\"content\":\"Say: Hi there!\"}],
        \"max_tokens\": 8
      }")
    end_time=$(date +%s.%3N)
    if echo "$resp" | grep -q '"choices"'; then
        echo "âœ… æˆåŠŸï¼Œè€—æ—¶ $(echo \"$end_time - $start_time\" | bc 2>/dev/null)s"
        echo "ğŸ—¨ï¸  å›å¤ï¼š$(echo "$resp" | jq -r '.choices[0].message.content' 2>/dev/null)"
    else
        echo "âŒ å¤±è´¥ï¼ŒåŸå§‹å“åº”ï¼š$resp"
    fi
}

manage_container() {
    case "$1" in
      start)   docker start $CONTAINER_NAME ;;
      stop)    docker stop $CONTAINER_NAME ;;
      restart) docker restart $CONTAINER_NAME ;;
      recreate) recreate_container ;;
      *) echo "ç”¨æ³•: $0 container {start|stop|restart|recreate}";;
    esac
}

show_help() {
    cat <<EOF
ğŸ³ ROCm vLLM + ModelScope ç®¡ç†è„šæœ¬

ç”¨æ³•: $0 {start|stop|restart|status|logs|follow|test|container}

å‘½ä»¤è¯´æ˜ï¼š
  start     - å®‰è£…/ä¸‹è½½(å¦‚éœ€)å¹¶å¯åŠ¨ vLLMï¼ˆä½¿ç”¨ ModelScope æœ¬åœ°æ¨¡å‹ï¼‰
  stop      - åœæ­¢ vLLM
  restart   - é‡å¯ vLLM
  status    - æ£€æŸ¥æœåŠ¡çŠ¶æ€
  logs      - æŸ¥çœ‹æ—¥å¿—
  follow    - å®æ—¶è·Ÿéšæ—¥å¿—
  test      - å‘é€æµ‹è¯•è¯·æ±‚
  container start|stop|restart|recreate - å®¹å™¨ç®¡ç†ï¼ˆrecreate ä¼šæŒ‚è½½ç¼“å­˜å¹¶æ˜ å°„ç«¯å£ï¼‰

å½“å‰é…ç½®ï¼š
  å®¹å™¨å: $CONTAINER_NAME
  é•œåƒ:   $IMAGE_NAME
  æ¨¡å‹ID: $MS_MODEL_ID
  æ¨¡å‹ç›®å½•(å®¿ä¸»/å®¹å™¨): $MODEL_DIR_HOST
  ç«¯å£:   $PORT
  æ—¥å¿—:   $LOG_DIR
EOF
}

case "$1" in
  start)    start_vllm ;;
  stop)     stop_vllm ;;
  restart)  restart_vllm ;;
  status)   check_service ;;
  logs)     show_logs ;;
  follow)   follow_logs ;;
  test)     test_service ;;
  container) manage_container "$2" ;;
  help|--help|-h|"") show_help ;;
  *) echo "âŒ æœªçŸ¥å‘½ä»¤: $1"; show_help; exit 1 ;;
esac
